{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd764177",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) & Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12ce717",
   "metadata": {},
   "source": [
    "## Load & Inspect Data\n",
    "This step loads the dataset, checks its shape, and provides a basic overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Dataset Shape: (3140, 108)\n",
      "\n",
      "ðŸ”¹ Dataset Info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3140 entries, 0 to 3139\n",
      "Columns: 108 entries, fips to Urban_rural_code\n",
      "dtypes: float64(61), int64(45), object(2)\n",
      "memory usage: 2.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load necessary libraries\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "health_data = pd.read_csv('https://raw.githubusercontent.com/4GeeksAcademy/regularized-linear-regression-project-tutorial/main/demographic_health_data.csv')\n",
    "\n",
    "# Dataset Overview: Check shape, info, and first few rows\n",
    "print(\"\\nðŸ”¹ Dataset Shape:\", health_data.shape)\n",
    "print(\"\\nðŸ”¹ Dataset Info:\\n\")\n",
    "print(health_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f54601a",
   "metadata": {},
   "source": [
    "### Handle Missing Values & Duplicates\n",
    "This step removes duplicate rows and fills missing values using the median for numeric columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f088a5",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "- Handles missing values\n",
    "- Removes duplicates\n",
    "- Encodes categorical variables\n",
    "- Drops highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Missing Values & Duplicates\n",
    "health_data.drop_duplicates(inplace=True) \n",
    "health_data.fillna(health_data.median(numeric_only=True), inplace=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d021e9",
   "metadata": {},
   "source": [
    "### Encode Categorical Variables\n",
    "Factorizes categorical columns into numerical representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical features using factorize() (instead of get_dummies)\n",
    "categorical_cols = health_data.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    health_data[col], _ = pd.factorize(health_data[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291f85fb",
   "metadata": {},
   "source": [
    "### Drop Highly Correlated Features\n",
    "Removes features with a correlation higher than 0.9 to avoid multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Dropped 63 highly correlated features.\n"
     ]
    }
   ],
   "source": [
    "# Remove Highly Correlated Features to Reduce Multicollinearity\n",
    "corr_matrix = health_data.corr().abs()\n",
    "upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.9)]\n",
    "\n",
    "health_data.drop(columns=to_drop, inplace=True)\n",
    "print(f\"\\nðŸ”¹ Dropped {len(to_drop)} highly correlated features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aa5701",
   "metadata": {},
   "source": [
    "## Data Normalization\n",
    "Standardizes the dataset using `StandardScaler` to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Final Dataset Shape: (3140, 45)\n",
      "\n",
      "ðŸ”¹ Sample Processed Data:\n",
      "        fips   TOT_POP  0-9 y/o % of total pop  10-19 y/o % of total pop  \\\n",
      "0 -1.940874 -0.145679                0.158006                  0.573496   \n",
      "1 -1.940742  0.341296               -0.242861                 -0.193107   \n",
      "2 -1.940610 -0.237785               -0.419441                 -0.439718   \n",
      "3 -1.940478 -0.245223               -0.426966                 -0.609076   \n",
      "4 -1.940346 -0.138966                0.186249                  0.216679   \n",
      "\n",
      "   20-29 y/o % of total pop  30-39 y/o % of total pop  \\\n",
      "0                  0.027610                  0.588469   \n",
      "1                 -0.469965                 -0.110300   \n",
      "2                  0.272104                  0.656538   \n",
      "3                  0.396168                  1.264959   \n",
      "4                 -0.200808                  0.088582   \n",
      "\n",
      "   40-49 y/o % of total pop  50-59 y/o % of total pop  \\\n",
      "0                  1.515069                  0.263445   \n",
      "1                  0.715673                  0.153177   \n",
      "2                  0.581419                 -0.237619   \n",
      "3                  1.461202                  0.256178   \n",
      "4                  0.994501                  0.023501   \n",
      "\n",
      "   60-69 y/o % of total pop  70-79 y/o % of total pop  ...  \\\n",
      "0                 -1.067889                 -0.503639  ...   \n",
      "1                  0.215895                  0.543366  ...   \n",
      "2                 -0.323597                  0.279761  ...   \n",
      "3                 -0.719016                 -0.319439  ...   \n",
      "4                 -0.450372                  0.056833  ...   \n",
      "\n",
      "   Active Physicians per 100000 Population 2018 (AAMC)  \\\n",
      "0                                          -0.894491     \n",
      "1                                          -0.894491     \n",
      "2                                          -0.894491     \n",
      "3                                          -0.894491     \n",
      "4                                          -0.894491     \n",
      "\n",
      "   Active General Surgeons per 100000 Population 2018 (AAMC)  COUNTY_NAME  \\\n",
      "0                                          -0.017028            -1.271003   \n",
      "1                                          -0.017028            -1.269157   \n",
      "2                                          -0.017028            -1.267311   \n",
      "3                                          -0.017028            -1.265465   \n",
      "4                                          -0.017028            -1.263619   \n",
      "\n",
      "   CNTY_FIPS  anycondition_prevalence  Obesity_prevalence  \\\n",
      "0  -0.952441                 0.126376            0.172860   \n",
      "1  -0.933866                -1.033783           -1.177782   \n",
      "2  -0.915291                 1.678482            1.257803   \n",
      "3  -0.896716                 0.753490            0.814969   \n",
      "4  -0.878141                -0.077436           -0.225690   \n",
      "\n",
      "   Heart disease_prevalence  COPD_prevalence  diabetes_prevalence  \\\n",
      "0                 -0.402548        -0.211219            -0.063696   \n",
      "1                 -0.459421        -0.211219            -0.394103   \n",
      "2                  1.360512         1.281578             2.432709   \n",
      "3                 -0.004438         0.385900             0.376846   \n",
      "4                  0.336800         0.599156             0.156575   \n",
      "\n",
      "   Urban_rural_code  \n",
      "0         -1.082865  \n",
      "1         -0.420704  \n",
      "2          0.903618  \n",
      "3         -1.745026  \n",
      "4         -1.745026  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "\n",
      "ðŸ”¹ Column names:\n",
      " Index(['fips', 'TOT_POP', '0-9 y/o % of total pop', '10-19 y/o % of total pop',\n",
      "       '20-29 y/o % of total pop', '30-39 y/o % of total pop',\n",
      "       '40-49 y/o % of total pop', '50-59 y/o % of total pop',\n",
      "       '60-69 y/o % of total pop', '70-79 y/o % of total pop',\n",
      "       '80+ y/o % of total pop', '% White-alone', 'Black-alone pop',\n",
      "       '% Black-alone', 'Native American/American Indian-alone pop',\n",
      "       '% NA/AI-alone', 'Asian-alone pop', '% Asian-alone',\n",
      "       'Hawaiian/Pacific Islander-alone pop', '% Hawaiian/PI-alone',\n",
      "       '% Two or more races', 'N_POP_CHG_2018', 'R_birth_2018', 'R_death_2018',\n",
      "       'R_NATURAL_INC_2018', 'R_INTERNATIONAL_MIG_2018', 'R_DOMESTIC_MIG_2018',\n",
      "       'Percent of adults with less than a high school diploma 2014-18',\n",
      "       'Percent of adults with a high school diploma only 2014-18',\n",
      "       'Percent of adults completing some college or associate's degree 2014-18',\n",
      "       'Percent of adults with a bachelor's degree or higher 2014-18',\n",
      "       'PCTPOVALL_2018', 'MEDHHINC_2018', 'Unemployment_rate_2018',\n",
      "       'Med_HH_Income_Percent_of_State_Total_2018',\n",
      "       'Active Physicians per 100000 Population 2018 (AAMC)',\n",
      "       'Active General Surgeons per 100000 Population 2018 (AAMC)',\n",
      "       'COUNTY_NAME', 'CNTY_FIPS', 'anycondition_prevalence',\n",
      "       'Obesity_prevalence', 'Heart disease_prevalence', 'COPD_prevalence',\n",
      "       'diabetes_prevalence', 'Urban_rural_code'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Normalize Data for Regularization using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "health_data_scaled = scaler.fit_transform(health_data)\n",
    "health_data = pd.DataFrame(health_data_scaled, columns=health_data.columns)\n",
    "\n",
    "# Final Dataset Info\n",
    "print(\"\\nðŸ”¹ Final Dataset Shape:\", health_data.shape)\n",
    "print(\"\\nðŸ”¹ Sample Processed Data:\\n\", health_data.head())\n",
    "print(\"\\nðŸ”¹ Column names:\\n\", health_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfacfe0",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "Divides the dataset into training and testing sets to evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split to Evaluate Model Performance\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Attempting to predict Obesity Rate\n",
    "y = health_data['Obesity_prevalence']\n",
    "X = health_data.drop(columns=['fips', 'CNTY_FIPS', 'COUNTY_NAME', 'Obesity_prevalence'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=117)\n",
    "\n",
    "# Fit Linear Regression Model & Evaluate Performance\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef518c2",
   "metadata": {},
   "source": [
    "## Linear Regression Model\n",
    "Fits a basic Linear Regression model and evaluates its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721356f8",
   "metadata": {},
   "source": [
    "### Fit Linear Regression Model\n",
    "Trains a basic linear regression model and evaluates its performance using MSE and RÂ² score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model intercept: 7.736401244703463e-05\n",
      "Model coefficients: [-1.13585036e-02  1.99482175e+06  1.70459095e+06  2.93604793e+06\n",
      "  1.59335323e+06  1.28938551e+06  1.39152443e+06  2.37838409e+06\n",
      "  2.08012784e+06  1.44161498e+06  3.04120110e+07  1.56339160e-02\n",
      "  2.69321900e+07 -1.64287148e-02  1.43642682e+07 -6.11199541e-03\n",
      "  5.31468898e+06  1.13117249e-02  1.80055127e+06  2.87297448e+06\n",
      "  6.73692216e-03 -4.96255976e-02  4.22269680e-02  4.74303985e-02\n",
      "  1.14765698e-02 -1.34418068e-02  3.73761579e-02  1.27718314e-01\n",
      "  7.62983433e-02  9.63972481e-02 -1.49968964e-02  2.95391287e-02\n",
      "  2.54505102e-04 -2.22292999e-02 -1.89619791e-02  3.55547433e-03\n",
      "  1.07988165e+00  5.58973543e-02 -3.03194341e-01  3.20326656e-02\n",
      "  1.00094801e-02]\n",
      "Model mean squared error: 0.10964813436065668\n",
      "Model r2 score: 0.8871106154713545\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f'Model intercept: {model.intercept_}')\n",
    "print(f'Model coefficients: {model.coef_}')\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(f'Model mean squared error: {mse}')\n",
    "print(f'Model r2 score: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cec742",
   "metadata": {},
   "source": [
    "## Lasso Regression (L1 Regularization)\n",
    "- Applies Lasso regression to improve generalization.\n",
    "- Tunes hyperparameters using GridSearchCV.\n",
    "- Evaluates optimized Lasso model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10629725",
   "metadata": {},
   "source": [
    "### Apply Lasso Regression\n",
    "Implements Lasso regression (L1 regularization) to improve generalization and feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667e17fd",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Lasso Regression\n",
    "Uses GridSearchCV to optimize the alpha parameter for Lasso regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2d38e1",
   "metadata": {},
   "source": [
    "### Evaluate Optimized Lasso Model\n",
    "Re-trains the Lasso model with the best alpha and evaluates its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 model mean squared error: 0.17380580276166482\n",
      "L1 model r2 score: 0.8210564163660614\n",
      "Best alpha: 0.0101\n",
      "L1 model mean squared error: 0.1125432522060905\n",
      "L1 model r2 score: 0.8841299165874691\n"
     ]
    }
   ],
   "source": [
    "# Apply Lasso Regression (L1 Regularization) to Improve Generalization\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "l1_model = Lasso(alpha=0.1,max_iter=200)\n",
    "l1_model.fit(X_train, y_train)\n",
    "\n",
    "l1_predictions = l1_model.predict(X_test)\n",
    "\n",
    "l1_mse = mean_squared_error(y_test, l1_predictions)\n",
    "l1_r2 = r2_score(y_test, l1_predictions)\n",
    "print(f'L1 model mean squared error: {l1_mse}')\n",
    "print(f'L1 model r2 score: {l1_r2}')\n",
    "\n",
    "# Hyperparameter Tuning for Lasso Regression using GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperparams = {\n",
    "    'alpha': np.arange(0.0001, 1.0, 0.01)\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(l1_model, hyperparams, scoring='r2', cv=5)\n",
    "\n",
    "# Suppress warnings due to incopatibilities or converges\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "best_alpha = grid.best_params_['alpha']\n",
    "print(f'Best alpha: {best_alpha}')\n",
    "\n",
    "# Re-run optimized Lasso model\n",
    "l1_model = Lasso(alpha=best_alpha,max_iter=200)\n",
    "l1_model.fit(X_train, y_train)\n",
    "\n",
    "l1_predictions = l1_model.predict(X_test)\n",
    "\n",
    "l1_mse = mean_squared_error(y_test, l1_predictions)\n",
    "l1_r2 = r2_score(y_test, l1_predictions)\n",
    "print(f'L1 model mean squared error: {l1_mse}')\n",
    "print(f'L1 model r2 score: {l1_r2}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
